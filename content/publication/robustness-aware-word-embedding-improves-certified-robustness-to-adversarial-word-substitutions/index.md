---
abstract: Natural Language Processing (NLP) models have gained great success on
  clean texts, but they are known to be vulnerable to adversarial examples
  typically crafted by synonym substitutions. In this paper, we target to solve
  this problem and find that word embedding is important to the certified
  robustness of NLP models. Given the findings, we propose the Embedding
  Interval Bound Constraint (EIBC) triplet loss to train robustness-aware word
  embeddings for better certified robustness.
slides: ""
url_pdf: ""
publication_types:
  - "1"
authors:
  - admin
  - Yichen Yang
  - Di He
  - Kun He
author_notes:
  - Equal contribution
  - Equal contribution
publication: In *Findings of ACL 2023*
summary: null
url_dataset: https://github.com/wowchemy/wowchemy-hugo-themes
url_project: ""
publication_short: ""
url_source: https://github.com/wowchemy/wowchemy-hugo-themes
url_video: https://youtube.com
title: Robustness-Aware Word Embedding Improves Certified Robustness to
  Adversarial Word Substitutions
doi: ""
featured: true
tags:
  - Adversaral Robustness
  - Certified Robustness
  - Natural Language Processing
projects: []
image:
  caption: "Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)"
  focal_point: ""
  preview_only: false
  filename: avatar.jpg
date: 2023-05-06T10:28:34.628Z
url_slides: ""
publishDate: 2023-06-01T00:00:00.000Z
url_poster: ""
url_code: https://github.com/wowchemy/wowchemy-hugo-themes
---

{{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the _Slides_ button to check out the example.
{{% /callout %}}

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
